{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc1fe40",
   "metadata": {},
   "source": [
    "数据相当于垃圾\n",
    "Dataset是为了把一些可回收的垃圾提取出来，并且给予它们编号，然后我们能从编号获取到特定的垃圾和label\n",
    "(提供一种方式去获取数据极其label)\n",
    "\n",
    "会有以下功能：\n",
    "1.如何获取每一个数据极其label；\n",
    "2.告诉我们总共有多少数据。\n",
    "\n",
    "\n",
    "Dataloader把那些可回收的垃圾打包(为后面的网络提供不同的数据形式)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95011cef",
   "metadata": {},
   "source": [
    "## Dataset 介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d570e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  torch.utils 表示torch的一些常用工具\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a26888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  Dataset(*args, **kwds)\n",
      " |  \n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getattr__(self, attribute_name)\n",
      " |  \n",
      " |  __getitem__(self, index) -> +T_co\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  register_datapipe_as_function(function_name, cls_to_register, enable_df_api_tracing=False) from builtins.type\n",
      " |  \n",
      " |  register_function(function_name, function) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'functions': typing.Dict[str, typing.Callable]}\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  functions = {'concat': functools.partial(<function Dataset.register_da...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e30faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个看得更方便\n",
    "Dataset??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d8131",
   "metadata": {},
   "source": [
    "## Dataset类代码实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b7e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, label_dir):\n",
    "        # 这个up主对self.xx 的理解是：相当于定义一个全局变量，普通的变量在函数之间不能相互共用\n",
    "        \n",
    "        self.root_dir = root_dir   # 这是根目录：dataset/train\n",
    "        self.label_dir = label_dir  # 这个数据集是 ants 和 bees 文件里单独存各自的数据集，相当于标签就是ants和bees\n",
    "        self.path = os.path.join(self.root_dir, self.label_dir)\n",
    "        # 获取所有图片的列表\n",
    "        self.img_path = os.listdir(self.path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_name = self.img_path[item]\n",
    "        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d2c41",
   "metadata": {},
   "source": [
    "# 测试一下是否能输出图片，路径是否对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32cfe084",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"E:\\code\\python_code\\Pytorch_gogo\\cs231n-2019-assignments-master\\Pytorch_learning_小土堆\\ant1.jpg\"\n",
    "img = Image.open(img_path)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7c58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"E:\\code\\python_code\\Pytorch_gogo\\cs231n-2019-assignments-master\\Pytorch_learning_小土堆\\dataset/train\"\n",
    "ants_label_dir = \"ants\"\n",
    "ants_dataset = MyData(root_dir, ants_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d4a60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333>, 'ants')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ants_dataset[1]  # 传出 img 和 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "109c5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = ants_dataset[1]\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab84753",
   "metadata": {},
   "source": [
    "加入蜜蜂的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa4b39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bees_label_dir = 'bees'\n",
    "bees_dataset = MyData(root_dir, bees_label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb9145",
   "metadata": {},
   "source": [
    "## 数据集的拼接， 比如有的时候数据集不够需要补充，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96fb1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ants_dataset + bees_dataset\n",
    "len(train_dataset)   # 245 = 124 + 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efc14b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset[123]\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1198301",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset[124]\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1dc58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch] *",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
